{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things one can focus at or pipeline sketch:\n",
    "\n",
    "1. [Build] Creating a robust and easy-implementable paraphrasing pipeline.\n",
    "\n",
    "2. [Modify] Creating a way to balance unbalanced datasets using paraphrasing (involves detection of imbalance)\n",
    "\n",
    "3. [Test]: Challenge existing text data augmentation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.func import *\n",
    "import pandas as pd\n",
    "df_w_semantics = semantic_similarity(pd.read_csv('data/paraphrasings.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_semantics\n",
    "# dataframe to csv\n",
    "df_w_semantics.to_csv('data/paraphrasings_w_semantics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before running this, run the following in the terminal: \n",
    "#1# CT_METAL=1 pip install ctransformers --no-binary ctransformers\n",
    "#2# pip install huggingface-hub\n",
    "#3# huggingface-cli download TheBloke/OpenHermes-2.5-Mistral-7B-GGUF openhermes-2.5-mistral-7b.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n",
    "\n",
    "\n",
    "# playing with mistral\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "from src.func import make_input_mistral, load_mistral, generate_dataframe\n",
    "import os\n",
    "\n",
    "\n",
    "prompt = make_input_mistral()\n",
    "\n",
    "model = load_mistral(os.path.join(\"model\", \"openhermes-2.5-mistral-7b.Q4_K_M.gguf\"))\n",
    "\n",
    "df = generate_dataframe(original, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:18<00:00,  6.95s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danmark kan ikke leve af gæld.</td>\n",
       "      <td>Økonomisk ubalancering vil vare i Danmark indt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efter et regeringsskifte vil den økonomiske po...</td>\n",
       "      <td>Efter et skift i regeringen, vil den nye økon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vi vil oprette et agentur mod falske nyheder, ...</td>\n",
       "      <td>Ønsket om at danne en organisation til bekæmpe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lige netop sygeskatten kunne have været et uds...</td>\n",
       "      <td>Ønsket om at indføre sygeskatten kunne have væ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HK, har ønsket at få kønsopdelt lønstatistik.</td>\n",
       "      <td>LO og DA kan også støtte HK's ønske om lønsta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Så jeg synes, det er ret svært, når man skal i...</td>\n",
       "      <td>\\n    Det virker ubedrageligt at tvange to så ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grænseoverskridende problemer må løses gennem ...</td>\n",
       "      <td>Grænseoverskridende problemer skal løses ved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Forskellen mellem virkningerne på beskæftigels...</td>\n",
       "      <td>Øget uddannelsesindsats er en faktor, der bidr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Det er sådan, at jeg lige har været inde at tj...</td>\n",
       "      <td>\\n    Så det var en læringstilfælde for dig? O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Det ene er at give borgerne mulighed for frit ...</td>\n",
       "      <td>Ønsket om at give borgerne mulighed for frit a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Derfor har vi også i den seneste folketingsper...</td>\n",
       "      <td>Så vi har imidlertid givet væbnets forsvar en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dansk Folkeparti har her fremsat et beslutning...</td>\n",
       "      <td>13. marts er beslutningsdatoen for EF-domstole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vi skal være bedre til at få nye idéer omsat t...</td>\n",
       "      <td>Vi skal forbedre vores evne til at omformuler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vi har selvfølgelig noteret os, at der ikke er...</td>\n",
       "      <td>\\n    Selvfølgelig har vi noteret det, og vi e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ved at starte en forbudsprocedure med udgangsp...</td>\n",
       "      <td>En forbudsprocedure baseret på lister over uø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mænd og kvinder og i øvrigt alle andre grupper...</td>\n",
       "      <td>Ønsket om ligestilling for begge køn og samme ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Undervejs har vi truffet hårde beslutninger.</td>\n",
       "      <td>Vi er nødt til at gennemføre tunga aftaler fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Regeringen magtede ikke at fortsætte en politi...</td>\n",
       "      <td>Økonomisk politik baseret på forsigtighed vil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Derfor undrer det mig, at der er så meget tviv...</td>\n",
       "      <td>Øjeblikkeligt, det er meget forunderligt, at d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Så det går da trods alt, også i forhold til ta...</td>\n",
       "      <td>\\n    Det går også at sige, at der er en retni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Original  \\\n",
       "0                      Danmark kan ikke leve af gæld.   \n",
       "1   Efter et regeringsskifte vil den økonomiske po...   \n",
       "2   Vi vil oprette et agentur mod falske nyheder, ...   \n",
       "3   Lige netop sygeskatten kunne have været et uds...   \n",
       "4       HK, har ønsket at få kønsopdelt lønstatistik.   \n",
       "5   Så jeg synes, det er ret svært, når man skal i...   \n",
       "6   Grænseoverskridende problemer må løses gennem ...   \n",
       "7   Forskellen mellem virkningerne på beskæftigels...   \n",
       "8   Det er sådan, at jeg lige har været inde at tj...   \n",
       "9   Det ene er at give borgerne mulighed for frit ...   \n",
       "10  Derfor har vi også i den seneste folketingsper...   \n",
       "11  Dansk Folkeparti har her fremsat et beslutning...   \n",
       "12  Vi skal være bedre til at få nye idéer omsat t...   \n",
       "13  Vi har selvfølgelig noteret os, at der ikke er...   \n",
       "14  Ved at starte en forbudsprocedure med udgangsp...   \n",
       "15  Mænd og kvinder og i øvrigt alle andre grupper...   \n",
       "16       Undervejs har vi truffet hårde beslutninger.   \n",
       "17  Regeringen magtede ikke at fortsætte en politi...   \n",
       "18  Derfor undrer det mig, at der er så meget tviv...   \n",
       "19  Så det går da trods alt, også i forhold til ta...   \n",
       "\n",
       "                                                  New  \n",
       "0   Økonomisk ubalancering vil vare i Danmark indt...  \n",
       "1    Efter et skift i regeringen, vil den nye økon...  \n",
       "2   Ønsket om at danne en organisation til bekæmpe...  \n",
       "3   Ønsket om at indføre sygeskatten kunne have væ...  \n",
       "4    LO og DA kan også støtte HK's ønske om lønsta...  \n",
       "5   \\n    Det virker ubedrageligt at tvange to så ...  \n",
       "6    Grænseoverskridende problemer skal løses ved ...  \n",
       "7   Øget uddannelsesindsats er en faktor, der bidr...  \n",
       "8   \\n    Så det var en læringstilfælde for dig? O...  \n",
       "9   Ønsket om at give borgerne mulighed for frit a...  \n",
       "10   Så vi har imidlertid givet væbnets forsvar en...  \n",
       "11  13. marts er beslutningsdatoen for EF-domstole...  \n",
       "12   Vi skal forbedre vores evne til at omformuler...  \n",
       "13  \\n    Selvfølgelig har vi noteret det, og vi e...  \n",
       "14   En forbudsprocedure baseret på lister over uø...  \n",
       "15  Ønsket om ligestilling for begge køn og samme ...  \n",
       "16   Vi er nødt til at gennemføre tunga aftaler fo...  \n",
       "17  Økonomisk politik baseret på forsigtighed vil ...  \n",
       "18  Øjeblikkeligt, det er meget forunderligt, at d...  \n",
       "19  \\n    Det går også at sige, at der er en retni...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "max_new_tokens = 50\n",
    "\n",
    "model = load_mistral(os.path.join(\"model\", \"openhermes-2.5-mistral-7b.Q4_K_M.gguf\"))\n",
    "\n",
    "strings = [\"Partiet Venstre er et borgerligt parti.\",\n",
    "           \"Social demokraterne var i regering fra 2011 til 2015.\",\n",
    "           \"Radikale venstre synes at skatten var for høj.\"]\n",
    "\n",
    "#for string in tqdm(original):\n",
    "#    new = model(make_input_mistral(string))\n",
    "#    print(f'[Original] {string} || [New] {new}')\n",
    "\n",
    "\n",
    "df = generate_dataframe(original, model)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>New</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Danmark kan ikke leve af gæld.</td>\n",
       "      <td>Økonomien ved uundgåelige skuldsatser truer me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efter et regeringsskifte vil den økonomiske po...</td>\n",
       "      <td>Så længe man tager foresigtsfyldt initiativer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vi vil oprette et agentur mod falske nyheder, ...</td>\n",
       "      <td>Vi skal danne en organisation til bekæmpelse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lige netop sygeskatten kunne have været et uds...</td>\n",
       "      <td>Ønsket om sygeskatteudspillet kunne have brugt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HK, har ønsket at få kønsopdelt lønstatistik.</td>\n",
       "      <td>Ønsker HK statistikker over lønninger opdelt e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Så jeg synes, det er ret svært, når man skal i...</td>\n",
       "      <td>Det er udmærket forståeligt, at det kan være ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Grænseoverskridende problemer må løses gennem ...</td>\n",
       "      <td>Økonomiske udfordringer kræver en internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Forskellen mellem virkningerne på beskæftigels...</td>\n",
       "      <td>Øget uddannelsesniveau blandt beskæftigede har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Det er sådan, at jeg lige har været inde at tj...</td>\n",
       "      <td>\\n    Det er sådan, at jeg lige har været inde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Det ene er at give borgerne mulighed for frit ...</td>\n",
       "      <td>\\n    Det ene er at give danskere frihed til a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Derfor har vi også i den seneste folketingsper...</td>\n",
       "      <td>Derfor har vi også i den seneste folketingspe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dansk Folkeparti har her fremsat et beslutning...</td>\n",
       "      <td>\\n    Dansk Folkeparti har indsendt et forslag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vi skal være bedre til at få nye idéer omsat t...</td>\n",
       "      <td>Vi skal forbedre vores evne til at omformuler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vi har selvfølgelig noteret os, at der ikke er...</td>\n",
       "      <td>\\n    Det være sig, at vi er bekendt med denne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ved at starte en forbudsprocedure med udgangsp...</td>\n",
       "      <td>Ønskede at starte en forbudsprocedure baseret ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mænd og kvinder og i øvrigt alle andre grupper...</td>\n",
       "      <td>Ældre og yngre, samt alle andre demografiske g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Undervejs har vi truffet hårde beslutninger.</td>\n",
       "      <td>Vi har taget vanskelige valg gennem vejen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Regeringen magtede ikke at fortsætte en politi...</td>\n",
       "      <td>Økonomisk politik, der ikke kan styrke virksom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Derfor undrer det mig, at der er så meget tviv...</td>\n",
       "      <td>Derfor forunder det mig, at der er så meget t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Så det går da trods alt, også i forhold til ta...</td>\n",
       "      <td>Trods alle udfordringer, går det også stadig ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Original  \\\n",
       "0                      Danmark kan ikke leve af gæld.   \n",
       "1   Efter et regeringsskifte vil den økonomiske po...   \n",
       "2   Vi vil oprette et agentur mod falske nyheder, ...   \n",
       "3   Lige netop sygeskatten kunne have været et uds...   \n",
       "4       HK, har ønsket at få kønsopdelt lønstatistik.   \n",
       "5   Så jeg synes, det er ret svært, når man skal i...   \n",
       "6   Grænseoverskridende problemer må løses gennem ...   \n",
       "7   Forskellen mellem virkningerne på beskæftigels...   \n",
       "8   Det er sådan, at jeg lige har været inde at tj...   \n",
       "9   Det ene er at give borgerne mulighed for frit ...   \n",
       "10  Derfor har vi også i den seneste folketingsper...   \n",
       "11  Dansk Folkeparti har her fremsat et beslutning...   \n",
       "12  Vi skal være bedre til at få nye idéer omsat t...   \n",
       "13  Vi har selvfølgelig noteret os, at der ikke er...   \n",
       "14  Ved at starte en forbudsprocedure med udgangsp...   \n",
       "15  Mænd og kvinder og i øvrigt alle andre grupper...   \n",
       "16       Undervejs har vi truffet hårde beslutninger.   \n",
       "17  Regeringen magtede ikke at fortsætte en politi...   \n",
       "18  Derfor undrer det mig, at der er så meget tviv...   \n",
       "19  Så det går da trods alt, også i forhold til ta...   \n",
       "\n",
       "                                                  New  \n",
       "0   Økonomien ved uundgåelige skuldsatser truer me...  \n",
       "1    Så længe man tager foresigtsfyldt initiativer...  \n",
       "2    Vi skal danne en organisation til bekæmpelse ...  \n",
       "3   Ønsket om sygeskatteudspillet kunne have brugt...  \n",
       "4   Ønsker HK statistikker over lønninger opdelt e...  \n",
       "5    Det er udmærket forståeligt, at det kan være ...  \n",
       "6   Økonomiske udfordringer kræver en internationa...  \n",
       "7   Øget uddannelsesniveau blandt beskæftigede har...  \n",
       "8   \\n    Det er sådan, at jeg lige har været inde...  \n",
       "9   \\n    Det ene er at give danskere frihed til a...  \n",
       "10   Derfor har vi også i den seneste folketingspe...  \n",
       "11  \\n    Dansk Folkeparti har indsendt et forslag...  \n",
       "12   Vi skal forbedre vores evne til at omformuler...  \n",
       "13  \\n    Det være sig, at vi er bekendt med denne...  \n",
       "14  Ønskede at starte en forbudsprocedure baseret ...  \n",
       "15  Ældre og yngre, samt alle andre demografiske g...  \n",
       "16         Vi har taget vanskelige valg gennem vejen.  \n",
       "17  Økonomisk politik, der ikke kan styrke virksom...  \n",
       "18   Derfor forunder det mig, at der er så meget t...  \n",
       "19   Trods alle udfordringer, går det også stadig ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Paraphrasing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "tokenizer_config.json: 100%|██████████| 1.61k/1.61k [00:00<00:00, 601kB/s]\n",
      "tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 1.46MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.80M/1.80M [00:01<00:00, 1.50MB/s]\n",
      "added_tokens.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 96.4kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 560/560 [00:00<00:00, 1.21MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "config.json: 100%|██████████| 613/613 [00:00<00:00, 1.26MB/s]\n",
      "model.safetensors.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 14.3MB/s]\n",
      "model-00001-of-00003.safetensors:   7%|▋         | 346M/4.94G [02:51<38:01, 2.02MB/s]\n",
      "Downloading shards:   0%|          | 0/3 [02:52<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/wibe/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/sandbox.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wibe/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/sandbox.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wibe/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/sandbox.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mberkeley-nest/Starling-LM-7B-alpha\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wibe/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/sandbox.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mberkeley-nest/Starling-LM-7B-alpha\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    568\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/transformers/modeling_utils.py:3128\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3125\u001b[0m \u001b[39m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3126\u001b[0m \u001b[39mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3127\u001b[0m     \u001b[39m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3128\u001b[0m     resolved_archive_file, sharded_metadata \u001b[39m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   3129\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3130\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3131\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   3132\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   3133\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   3134\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   3135\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   3136\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   3137\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   3138\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   3139\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   3140\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   3141\u001b[0m     )\n\u001b[1;32m   3143\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3144\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3145\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(resolved_archive_file, \u001b[39mstr\u001b[39m)\n\u001b[1;32m   3146\u001b[0m     \u001b[39mand\u001b[39;00m resolved_archive_file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.safetensors\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3147\u001b[0m ):\n\u001b[1;32m   3148\u001b[0m     \u001b[39mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/transformers/utils/hub.py:1052\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[39mfor\u001b[39;00m shard_filename \u001b[39min\u001b[39;00m tqdm(shard_filenames, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading shards\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1050\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1051\u001b[0m         \u001b[39m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m         cached_filename \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m   1053\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   1054\u001b[0m             shard_filename,\n\u001b[1;32m   1055\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1056\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   1057\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1058\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   1059\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1060\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1061\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1062\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1063\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   1064\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49m_commit_hash,\n\u001b[1;32m   1065\u001b[0m         )\n\u001b[1;32m   1066\u001b[0m     \u001b[39m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m     \u001b[39m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    428\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    431\u001b[0m         path_or_repo_id,\n\u001b[1;32m    432\u001b[0m         filename,\n\u001b[1;32m    433\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    434\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    435\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    436\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    437\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    438\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    439\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    440\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    441\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    442\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    446\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    447\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/huggingface_hub/file_download.py:1461\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m             _check_disk_space(expected_size, local_dir)\n\u001b[0;32m-> 1461\u001b[0m     http_get(\n\u001b[1;32m   1462\u001b[0m         url_to_download,\n\u001b[1;32m   1463\u001b[0m         temp_file,\n\u001b[1;32m   1464\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1465\u001b[0m         resume_size\u001b[39m=\u001b[39;49mresume_size,\n\u001b[1;32m   1466\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1467\u001b[0m         expected_size\u001b[39m=\u001b[39;49mexpected_size,\n\u001b[1;32m   1468\u001b[0m     )\n\u001b[1;32m   1470\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1471\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/huggingface_hub/file_download.py:541\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, _nb_retries)\u001b[0m\n\u001b[1;32m    539\u001b[0m new_resume_size \u001b[39m=\u001b[39m resume_size\n\u001b[1;32m    540\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 541\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    542\u001b[0m         \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    543\u001b[0m             progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 628\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    630\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    631\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/Exam_project/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/urllib3/response.py:525\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     chunk_amt \u001b[39m=\u001b[39m max_chunk_amt\n\u001b[0;32m--> 525\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(chunk_amt)\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m    527\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"berkeley-nest/Starling-LM-7B-alpha\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"berkeley-nest/Starling-LM-7B-alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27.7\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# show version of openai\n",
    "print(openai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"\"\"\n",
    "1.\tDanmark kan ikke leve af gæld.\n",
    "2.\tEfter et regeringsskifte vil den økonomiske politik bygge på et meget klart forsigtighedsprincip.\n",
    "3.\tVi vil oprette et agentur mod falske nyheder, der udarbejder modsvar og korrigerer falske nyhedshistorier i Danmark.\n",
    "4.\tLige netop sygeskatten kunne have været et udspil, som LO og DA kunne have brugt selv til at få forhandlingerne på gled igen - alt i alt et indgreb og en lovgivning, der er tydeligt præget af at være udarbejdet af politikere fra Overdanmark med funktionærverdenen som eneste erfaringsgrundlag og uden særlig meget viden om, hvor skoen trykker.\n",
    "5.\tHK har ønsket at få kønsopdelt lønstatistik.\n",
    "6.\tSå jeg synes, det er ret svært, når man skal igennem de her ting, og jeg synes heller ikke, vi kan være bekendt, at noget, der er så vigtigt som forbrugernes sikkerhed, når det gælder medicin, skal puttes ind sammen med en hel masse andre ting.\n",
    "7.\tGrænseoverskridende problemer må løses gennem et grænseoverskridende samarbejde.\n",
    "8.\tForskellen mellem virkningerne på beskæftigelse og arbejdsløshed ligger i den øgede uddannelsesindsats.\n",
    "9.\tDet er sådan, at jeg lige har været inde at tjekke min ordførertale, så jeg ikke skulle få samme svada fra hr.\n",
    "10.\tDet ene er at give borgerne mulighed for frit at kunne rejse rundt i Europa, så de f.eks. ikke skal stå i lange køer, når de skal på ferie nede sydpå.\n",
    "11.\tDerfor har vi også i den seneste folketingsperiode givet forsvaret det substantielle løft, som vi lovede, at der ville komme.\n",
    "12.\tDansk Folkeparti har her fremsat et beslutningsforslag, der pålægger regeringen at arbejde for en ændring af reglerne for EF-Domstolens arbejde, og så vidt jeg ved, skal det drøftes den 13. marts.\n",
    "13.\tVi skal være bedre til at få nye idéer omsat til produktion.\n",
    "14.\tVi har selvfølgelig noteret os, at der ikke er flertal for vores forslag.\n",
    "15.\tVed at starte en forbudsprocedure med udgangspunkt i listen over uønskede stoffer og de hormonforstyrrende kategori 1-stoffer i kosmetik tages et vigtigt skridt i den rigtige retning.\n",
    "16.\tMænd og kvinder og i øvrigt alle andre grupper skal have lige muligheder for at udfylde deres personlige potentiale.\n",
    "17.\tUndervejs har vi truffet hårde beslutninger.\n",
    "18.\tRegeringen magtede ikke at fortsætte en politik, som kunne forbedre erhvervslivets forhold.\n",
    "19.\tDerfor undrer det mig, at der er så meget tvivl, og at man kan tro, at vi vil tage 20 pct. af de unge mennesker ind i den her ordning.\n",
    "20.\tSå det går da trods alt, også i forhold til tallene fra sidste år, den rigtige vej.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import openai\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Paraphrase the following sentence (in Danish): \"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Danmark kan ikke overleve ved at have gæld.\\n2. Efter et regeringsskifte vil den økonomiske politik være baseret på et klart forsigtighedsprincip.\\n3. Vi vil etablere en agentur mod falske nyheder, som vil udarbejde modsvar og rette falske nyhedshistorier i Danmark.\\n4. Netop sygeskat kunne have været et udspil, som LO og DA selv kunne have brugt til at få forhandlingerne på sporet igen - alt i alt en indgriben og lovgivning, som tydeligvis er udviklet af politikere fra Overdanmark med kun funktionsverdenen som deres erfaringsgrundlag og uden særlig meget viden om, hvor problemet ligger.\\n5. HK har ønsket at få opdelt lønstatistik efter køn.\\n6. Så jeg synes, det er ret svært, når man skal igennem alt dette, og jeg synes heller ikke, at det er forsvarligt, at noget, der er så vigtigt som forbrugernes sikkerhed vedrørende medicin, bliver bundtet sammen med en masse andre ting.\\n7. Problemer på tværs af grænser skal løses gennem et internationalt samarbejde.\\n8. Forskellen mellem effekten på beskæftigelse og arbejdsløshed ligger i den øgede fokus på uddannelse.\\n9. Sådan er det, lige efter jeg har tjekket min ordførertale, så jeg ikke får samme nedsmeltning fra hr.\\n10. Det ene er at give borgerne mulighed for frit at rejse rundt i Europa, så de ikke skal stå i lange køer, når de skal på ferie sydpå.\\n11. Derfor har vi i den seneste folketingssession også givet forsvaret det betydelige løft, vi lovede.\\n12. Dansk Folkeparti har fremsat et beslutningsforslag her, der pålægger regeringen at arbejde for en ændring af EF-Domstolens funktion, og så vidt jeg ved, skal det drøftes den 13. marts.\\n13. Vi skal blive bedre til at omsætte nye idéer til produktion.\\n14. Vi har naturligvis noteret os, at vores forslag ikke har flertal.\\n15. Ved at igangsætte en forbudsprocedure baseret på listen over uønskede stoffer og kategori 1 hormonforstyrrende stoffer i kosmetik, tager vi et vigtigt skridt i den rigtige retning.\\n16. Mænd og kvinder, og i virkeligheden alle andre grupper, skal have lige muligheder for at opfylde deres personlige potentiale.\\n17. Undervejs har vi truffet svære beslutninger.\\n18. Regeringen var ikke i stand til at fortsætte en politik, der kunne forbedre forholdene for erhvervslivet.\\n19. Derfor undrer det mig, at der er så meget tvivl, og at man kan tro, at vi vil inkludere 20 pct. af de unge i denne ordning.\\n20. Så det går da fremad, også i forhold til tallene fra sidste år.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show completed chat\n",
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.987843]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"This is example sentence\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "#print(embeddings)\n",
    "\n",
    "# print cosine-similarities betwen the sentences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity([embeddings[0]], [embeddings[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1731\n",
      "1732\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "paraphrasings = pd.read_csv(\"data/paraphrasings_new.csv\")\n",
    "paraphrased_texts = paraphrasings[\"New\"].tolist()\n",
    "\n",
    "print(len(paraphrased_texts))\n",
    "\n",
    "original = pd.read_csv(\"data/train_data.csv\")\n",
    "original_texts = original[\"text\"].tolist()\n",
    "print(len(original_texts))\n",
    "\n",
    "\n",
    "\n",
    "# concatenate the two dataframes\n",
    "#df = pd.concat([original, paraphrasings], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Det kan jo slet ikke forslå. Men den regnemeto...\n",
       "1       Tidligere kunne fortælle, at en tysk burgerkæd...\n",
       "2       Nej. Og det er jeg også imod per princip. Man ...\n",
       "3       Jeg synes faktisk, det sprogligt har været svæ...\n",
       "4       Den er faktisk lidt sjov. Hvem er homofobisk -...\n",
       "                              ...                        \n",
       "1727    🔥🔥 at du ikke har Bosa på. Er det hans seneste...\n",
       "1728    Interessant medieinitiativ på Nørrebro #dkmedi...\n",
       "1729    #ElskDenDuVil\\n@USER #fckob\\nGi’ homofobien 🏳️...\n",
       "1730    Domstol lukker thailandsk parti for at nominer...\n",
       "1731    ⚽️ Der er i dag 1 #fodbold kampe/events mere, ...\n",
       "Name: text, Length: 1732, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 Efter et politisk skift vil økonomien bygge på meget sikre beslutninger.\\n    1 Et nyt regeringsskifte vil føre til en helt nyskabende økonomisk politik, grundet størst forsigtighed.\\n    2 Vi skal danne et foretagen mod u Sand News, der arbejder på at udvikle svar og rette urigtige nyheder i Danmark.\\n    3 LO og DA kunne have brugt sygeskatten som udspil for genoptagelsen af forhandlinger - en politisk handling skabt af repræsentanter for bedre klasse baseret på funktionærkunderkundskab og uden indsigt i konkrete problemer.\\n    4 HK ønsker statistikker over lønninger, opdelt efter køn, og det ville være interessant at se, hvor meget forskel der er mellem mænd og kvinder.', '2. Er der et regeringsskifte, vil den nye økonomiske politik være baseret på en meget', '2. Danmark kan ikke leve af gæld -> 2. Det er uundgåeligt, at skifte i regeringen vil føre til en forsigtigere økonomisk politik.\\n    3. Efter et regeringsskifte vil den økonomiske politik bygge på et meget klart forsigtighedsprincip -> 3. En nye regering vil være trued af skiftende økonomiske politikker.\\n    4. Vi vil oprette et agentur mod falske nyheder, der udarbejder modsvar og korrigerer falske nyhedshistorier i Danmark -> 4. Et nyt regeringsskifte vil føre til oprettelsen af en organisation, der arbejder for at bekæmpe fake news og rette urigtige nyheder.\\n    5. Sygeskatten kunne have været noget, som LO og DA kunne have brugt selv til selv at sætte gang i forhandlingerne igen - i sidste ende en politisk handling og lovgivning, der tydeligvis er skabt af politikere fra den bedre del af samfundet, kun baseret på erfaringer fra administrativt arbejde og med begrænset indsigt i de konkrete problemer. -> 5. Lønorganisationerne LO og DA kunne have anvendt sygeskatten som et middel til at genoptage forhandlinger, der imidlertid viser sig at være politisk motiverede og tydeligvis udarbejdet af politikere fra Overdanmark med funktionærverdenen som eneste erfaringsgrundlag og uden særlig meget viden om, hvor skoen trykker.\\n    6. HK har udtrykt ønske om statistikker over lønninger opdelt efter køn. -> 6. HK fremhæver behovet for statistikker angående lønninger, som er inddelt efter køn.']\n",
      "['Det kan jo slet ikke forslå. Men den regnemetode som Finansministeriet benytter skal du forvente at der skal forhøjes med yderligere kr. 225.000 oven i det som den enkelte skal have.\\nDet bliver megadyret og er vel grunden til at V ikke har fremlagt noget. #dkpol', 'Tidligere kunne fortælle, at en tysk burgerkæde er på vej, i sidste uge, at Garage Burger åbner i Fredericia og snart kan vi også se frem til en ny restaurant i det gamle Kims Køkken i Jyllandsgade 47.', 'Nej. Og det er jeg også imod per princip. Man må heller ikke rende på Farum Park med et banner der står \"Free Brixtofte\" på. Jeg læste - måske mellem linjerne - som at at \\'nedsættende\\' chants skal være forbudte. Og her kræver det altså lige noget omtanke. Der er ikke noget ..']\n"
     ]
    }
   ],
   "source": [
    "print(paraphrased_texts[0:3])\n",
    "print(original_texts[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
