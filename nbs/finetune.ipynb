{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning BERT\n",
    "Notebook containing the steps necesarry to fine-tune BERT on paraphrased dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Data paths\n",
    "\n",
    "# path to the original Twitter data\n",
    "path = os.path.join(\"..\" , \"data\" , \"original_Twitter_data.csv\")\n",
    "\n",
    "# path to the original Twitter data with 1st round of paraphrased tweets, with Mistral\n",
    "path2 = os.path.join(\"..\" , \"data\" , \"train_paraphrased_w_mistral_seed42_1.csv\")\n",
    "\n",
    "# path to the original Twitter data with 2nd round of paraphrased tweets, with Mistral\n",
    "path3 = os.path.join(\"..\" , \"data\" , \"train_paraphrased_w_mistral_seed42_2.csv\")\n",
    "\n",
    "# path to the original Twitter data paraphrased with GPT-4\n",
    "path4 = os.path.join(\"..\" , \"data\" , \"train_paraphrased_with_gpt4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chunk contains the four functions\n",
    "1. Function to **load and prepare dataset**\n",
    "2. Function to **split dataset into test, train and validation sets**\n",
    "3. Function to **tokenize dataset**\n",
    "4. Function **defining evaluation metrics** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "import pandas as pd\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "####################################################\n",
    "#####                LOADING DATA              #####\n",
    "####################################################\n",
    "def load_and_prepare_dataset(file_path):\n",
    "    # Load the dataset\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    #print the number of times a label is positive, negative or neutral\n",
    "    print(f\"Number of labels in each category: {dataset['label'].value_counts()}\")\n",
    "    # equalize dataset making sure there are the same number of positive, negative and neutral tweets\n",
    "    # Remove all rows where language is not 'da'\n",
    "    dataset = dataset[dataset['language'] == 'da']\n",
    "    # Remove all columns except 'text' and 'label'\n",
    "    dataset = dataset[['text', 'label']]\n",
    "    # Remove all duplicates\n",
    "    dataset = dataset.drop_duplicates()\n",
    "    # Convert to dict and then to a Hugging Face Dataset\n",
    "    dataset = Dataset.from_dict(dataset)\n",
    "    print(\"Dataset loaded and prepared\")\n",
    "    return dataset#, dataset_pd\n",
    "\n",
    "\n",
    "####################################################\n",
    "##### SPLIT DATASET INTO TRAIN, VALID AND TEST #####\n",
    "####################################################\n",
    "def split_dataset(dataset, path, seed=42): #def split_dataset(dataset, path_to_df_train, path_to_df_train_2, seed=42):\n",
    "    \n",
    "    # load paraphrasings dataset\n",
    "    paraphrasings = pd.read_csv(path)\n",
    "\n",
    "    # Keep only paraphrasings from the dataset\n",
    "    paraphrasings = paraphrasings[paraphrasings['org_or_new'] == 0]\n",
    "    print(\"Number of paraphrasings: \", len(paraphrasings))\n",
    "\n",
    "    paraphrasings = paraphrasings.rename(columns={\"New\":\"text\"})\n",
    "    paraphrasings = paraphrasings.drop(columns=[\"org_or_new\"])\n",
    "\n",
    "    # rename paraphrased_text to text\n",
    "    paraphrasings = paraphrasings.rename(columns={\"paraphrased_text\":\"text\"})\n",
    "\n",
    "    paraphrasings_plus_org = Dataset.from_dict(paraphrasings)\n",
    "\n",
    "\n",
    "    # 60% train, 20% validation, 20% test\n",
    "    train_test = dataset.train_test_split(test_size=0.4, seed=seed) \n",
    "    test_valid = train_test['test'].train_test_split(test_size=0.5, seed=seed)\n",
    "\n",
    "    # combine train, test and valid to one dictionary\n",
    "    dataset_splitted_dict = DatasetDict({\n",
    "        'train': paraphrasings_plus_org,\n",
    "        'valid': test_valid['train'],\n",
    "        'test': test_valid['test']})\n",
    "    \n",
    "    print(\"Dataset splitted into train (60%), valid (20%) and test (20%)\")\n",
    "\n",
    "    # output the train dataset as a csv file\n",
    "    #dataset_splitted_dict['train'].to_csv(os.path.join(\"..\", \"data\", \"train.csv\"))\n",
    "\n",
    "    # print the length of the train dataset\n",
    "    print(\"Length of train dataset: \", len(dataset_splitted_dict['train']))\n",
    "    print(\"Length of valid dataset: \", len(dataset_splitted_dict['valid']))\n",
    "    print(\"Length of test dataset: \", len(dataset_splitted_dict['test']))\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    return dataset_splitted_dict\n",
    "\n",
    "####################################################\n",
    "#####             TOKENIZE DATASET             #####\n",
    "####################################################\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import ClassLabel\n",
    "\n",
    "def tokenize_dataset(dataset, model_name=\"NbAiLab/nb-bert-large\", max_length=128):\n",
    "    # defining the labels\n",
    "    labels_cl = ClassLabel(num_classes=3, names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "    # load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # defining a function to tokenize the text and translate all labels into integers instead of strings\n",
    "    def tokenize_function(example):\n",
    "        tokens = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "        tokens['label'] = labels_cl.str2int(example['label'])\n",
    "        return tokens\n",
    "\n",
    "    # actually tokenizing the dataset\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset['train'].column_names) # batched=True speeds up tokenization by allowing to process multiple lines at once\n",
    "\n",
    "\n",
    "    print(\"Dataset tokenized\")\n",
    "\n",
    "    return tokenized_dataset\n",
    "\n",
    "####################################################\n",
    "#####              EVALUATION METRICS          #####\n",
    "####################################################\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric0 = evaluate.load(\"accuracy\")\n",
    "    metric1 = evaluate.load(\"precision\")\n",
    "    metric2 = evaluate.load(\"recall\")\n",
    "    metric3 = evaluate.load(\"f1\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric0.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
    "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
    "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing dataset...\n",
      "Number of labels in each category: label\n",
      "negative    1525\n",
      "neutral     1281\n",
      "positive    1000\n",
      "Name: count, dtype: int64\n",
      "Dataset loaded and prepared\n",
      "Splitting dataset...\n",
      "Number of paraphrasings:  1174\n",
      "Dataset splitted into train (60%), valid (20%) and test (20%)\n",
      "Length of train dataset:  1174\n",
      "Length of valid dataset:  714\n",
      "Length of test dataset:  715\n",
      "\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tokenizer_config.json: 100%|██████████| 506/506 [00:00<00:00, 14.8kB/s]\n",
      "\n",
      "\u001b[A\n",
      "sentencepiece.bpe.model: 100%|██████████| 1.09M/1.09M [00:00<00:00, 2.32MB/s]\n",
      "\n",
      "\u001b[A\n",
      "tokenizer.json: 100%|██████████| 3.80M/3.80M [00:00<00:00, 5.79MB/s]\n",
      "\n",
      "special_tokens_map.json: 100%|██████████| 167/167 [00:00<00:00, 54.5kB/s]\n",
      "\n",
      "Map: 100%|██████████| 1174/1174 [00:00<00:00, 14542.82 examples/s]\n",
      "\n",
      "Map: 100%|██████████| 714/714 [00:00<00:00, 20099.69 examples/s]\n",
      "\n",
      "Map: 100%|██████████| 715/715 [00:00<00:00, 20643.82 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tokenized\n",
      "Loading model (NbAiLab/nb-bert-large)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "config.json: 100%|██████████| 548/548 [00:00<00:00, 205kB/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model.safetensors: 100%|██████████| 498M/498M [00:20<00:00, 23.8MB/s]\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at vesteinn/DanskBERT and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preparing dataset...\")\n",
    "dataset = load_and_prepare_dataset(path)\n",
    "\n",
    "print(\"Splitting dataset...\")\n",
    "dataset_splitted_dict = split_dataset(dataset, path2) #split_dataset(dataset, path2, path3)\n",
    "\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = tokenize_dataset(dataset_splitted_dict)\n",
    "\n",
    "print(\"Loading model (NbAiLab/nb-bert-large)...\")\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"NbAiLab/nb-bert-large\", num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['negative', 'neutral', 'positive'], dtype='<U8'), array([468, 379, 327]))\n",
      "(array(['negative', 'neutral', 'positive'], dtype='<U8'), array([309, 221, 185]))\n",
      "(array(['negative', 'neutral', 'positive'], dtype='<U8'), array([268, 252, 194]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "# count number of labels in each dataset\n",
    "print(np.unique(dataset_splitted_dict['train']['label'],return_counts=True))\n",
    "print(np.unique(dataset_splitted_dict['test']['label'],return_counts=True))\n",
    "print(np.unique(dataset_splitted_dict['valid']['label'],return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 8 # stating batch size\n",
    "epochs = 4\n",
    "learning_rate = 1e-5\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  num_train_epochs=epochs,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  weight_decay=0.01,\n",
    "                                  logging_dir=\"logs\",\n",
    "                                  logging_steps=10,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",  # Add this line\n",
    "                                  remove_unused_columns=False,\n",
    "                                  run_name=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/588 [13:34<66:18:38, 407.37s/it]\n",
      "  2%|▏         | 10/588 [00:37<21:20,  2.22s/it] \n",
      "  2%|▏         | 10/588 [00:37<21:20,  2.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0765, 'learning_rate': 9.829931972789115e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/588 [00:42<23:34,  2.46s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# specify the range which is the number of fine-tuning runs you want to do. Default is 10.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):    \n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/transformers/trainer.py:1910\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m   1905\u001b[0m             model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m   1906\u001b[0m             args\u001b[38;5;241m.\u001b[39mmax_grad_norm,\n\u001b[1;32m   1907\u001b[0m         )\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 1910\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1911\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/accelerate/optimizer.py:145\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    171\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    174\u001b[0m         group,\n\u001b[1;32m    175\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         state_steps,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 335\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/adamw.py:413\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    412\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 413\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    416\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# specify the range which is the number of fine-tuning runs you want to do. Default is 10.\n",
    "for i in range(2):    \n",
    "    trainer.train()\n",
    "\n",
    "    trainer.evaluate()\n",
    "\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # creating model predictions for the validation data\n",
    "    predictions_val = trainer.predict(tokenized_dataset[\"valid\"])\n",
    "\n",
    "    # choosing the prediction that has the highest probability \n",
    "    preds_val_val = np.argmax(predictions_val.predictions, axis=-1)\n",
    "\n",
    "    # calculating the probabilities instead of logits from each\n",
    "    predictions_probabilities = tf.nn.softmax(predictions_val.predictions)\n",
    "\n",
    "    def compute_metrics_end(preds, refs):\n",
    "        metric0 = evaluate.load(\"accuracy\")\n",
    "        metric1 = evaluate.load(\"precision\")\n",
    "        metric2 = evaluate.load(\"recall\")\n",
    "        metric3 = evaluate.load(\"f1\")\n",
    "        \n",
    "        #logits, labels = eval_pred\n",
    "        #predictions = np.argmax(logits, axis=-1)\n",
    "        accuracy = metric0.compute(predictions=preds, references=refs)[\"accuracy\"]\n",
    "        precision = metric1.compute(predictions=preds, references=refs, average=\"weighted\")[\"precision\"]\n",
    "        recall = metric2.compute(predictions=preds, references=refs, average=\"weighted\")[\"recall\"]\n",
    "        f1 = metric3.compute(predictions=preds, references=refs, average=\"weighted\")[\"f1\"]\n",
    "        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "    metrics_val = compute_metrics_end(preds=preds_val_val, refs=predictions_val.label_ids)\n",
    "\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # creating model predictions for the validation data\n",
    "    predictions_test = trainer.predict(tokenized_dataset[\"test\"])\n",
    "\n",
    "    # choosing the prediction that has the highest probability \n",
    "    preds_test_test = np.argmax(predictions_test.predictions, axis=-1)\n",
    "\n",
    "    # calculating the probabilities instead of logits from each\n",
    "    predictions_probabilities_test = tf.nn.softmax(predictions_test.predictions)\n",
    "\n",
    "    metrics_test = compute_metrics_end(preds=preds_test_test, refs=predictions_test.label_ids)\n",
    "\n",
    "    print(metrics_test)\n",
    "    print(metrics_val)\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    data = {'Predicted Labels': [\"negative\" if i == 0 else \"neutral\" if i == 1 else \"positive\" for i in preds_val_val],\n",
    "            'True Labels': [\"negative\" if i == 0 else \"neutral\" if i == 1 else \"positive\" for i in predictions_val.label_ids],\n",
    "            'Misclassification': [\"TRUE\" if preds_val_val[i] == predictions_val.label_ids[i] else 'MISS' for i, val in enumerate(preds_val_val)],\n",
    "            'Text': dataset_splitted_dict['valid']['text'],\n",
    "            'Logit Values': [str(i) for i in predictions_val.predictions],\n",
    "            'Probabilities': [str(i) for i in np.asarray(predictions_probabilities)]}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # Extract the true and predicted labels\n",
    "    true_labels = df['True Labels']\n",
    "    predicted_labels = df['Predicted Labels']\n",
    "\n",
    "    # Create a mapping for the labels to numbers if needed\n",
    "    label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "    # Map the labels to numbers using the mapping\n",
    "    true_labels_mapped = true_labels.map(label_mapping)\n",
    "    predicted_labels_mapped = predicted_labels.map(label_mapping)\n",
    "\n",
    "    # Generate the classification report\n",
    "    report = classification_report(true_labels_mapped, predicted_labels_mapped, target_names=label_mapping.keys(), output_dict=True)\n",
    "\n",
    "    # save classification report to csv\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "\n",
    "    # change the name of the output according to what you're testing\n",
    "    df.to_csv(f\"../classification_reports_twitter/{i+1}classification_report_org_twitter_plus_1x_mistral_para.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_NLP_exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
