{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Data path\n",
    "path = os.path.join(\"..\" , \"data\" , \"tweets_data_temp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "\n",
    "def load_and_prepare_dataset(file_path):\n",
    "    # Load the dataset\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    \n",
    "    #print the number of times a label is positive, negative or neutral\n",
    "    print(dataset['label'].value_counts())\n",
    "    # equalize dataset making sure there are the same number of positive, negative and neutral tweets\n",
    "    dataset = dataset.groupby('label').head(1000).reset_index(drop=True)\n",
    "    print(f'New sizes: {dataset[\"label\"].value_counts()}')\n",
    "    dataset = dataset[:100]\n",
    "\n",
    "    # Remove all rows where language is not 'da'\n",
    "    dataset = dataset[dataset['language'] == 'da']\n",
    "\n",
    "    # Remove all columns except 'text' and 'label'\n",
    "    dataset = dataset[['text', 'label']]\n",
    "\n",
    "    # Remove all duplicates\n",
    "    dataset = dataset.drop_duplicates()\n",
    "\n",
    "    dataset_pd = dataset[:300]\n",
    "\n",
    "    # Convert to dict and then to a Hugging Face Dataset\n",
    "    dataset = Dataset.from_dict(dataset)\n",
    "\n",
    "    print(\"Dataset loaded and prepared\")\n",
    "    print(dataset)\n",
    "\n",
    "    return dataset, dataset_pd\n",
    "\n",
    "# Split the dataset and convert into a Hugging Face DatasetDict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "def split_dataset(dataset, seed=42):\n",
    "    # 60% train, 20% validation, 20% test\n",
    "    train_test = dataset.train_test_split(test_size=0.4, seed=seed) \n",
    "    test_valid = train_test['test'].train_test_split(test_size=0.5, seed=seed)\n",
    "\n",
    "    # combine train, test and valid to one dictionary\n",
    "    dataset_splitted_dict = DatasetDict({\n",
    "        'train': train_test['train'],\n",
    "        'valid': test_valid['train'],\n",
    "        'test': test_valid['test']})\n",
    "    \n",
    "    print(\"Dataset splitted into train (60%), valid (20%) and test (20%)\")\n",
    "\n",
    "    # output the train dataset as a csv file\n",
    "    dataset_splitted_dict['train'].to_csv(os.path.join(\"..\", \"data\", \"train.csv\"))\n",
    "\n",
    "    # print the length of the train dataset\n",
    "    print(\"Length of train dataset: \", len(dataset_splitted_dict['train']))\n",
    "    print(\"Length of valid dataset: \", len(dataset_splitted_dict['valid']))\n",
    "    print(\"Length of test dataset: \", len(dataset_splitted_dict['test']))\n",
    "\n",
    "    return dataset_splitted_dict\n",
    "\n",
    "# Tokenize the dataset \n",
    "from transformers import AutoTokenizer\n",
    "from datasets import ClassLabel\n",
    "\n",
    "def tokenize_dataset(dataset, model_name=\"cardiffnlp/twitter-xlm-roberta-base\", max_length=128):\n",
    "    # defining the labels\n",
    "    labels_cl = ClassLabel(num_classes=3, names=['negative', 'neutral', 'positive'])\n",
    "\n",
    "    # load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # defining a function to tokenize the text and translate all labels into integers instead of strings\n",
    "    def tokenize_function(example):\n",
    "        tokens = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=max_length)\n",
    "        tokens['label'] = labels_cl.str2int(example['label'])\n",
    "        return tokens\n",
    "\n",
    "    # actually tokenizing the dataset\n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset['train'].column_names) # batched=True speeds up tokenization by allowing to process multiple lines at once\n",
    "\n",
    "\n",
    "    print(\"Dataset tokenized\")\n",
    "\n",
    "    return tokenized_dataset\n",
    "\n",
    "# evaluation metrics\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric0 = evaluate.load(\"accuracy\")\n",
    "    metric1 = evaluate.load(\"precision\")\n",
    "    metric2 = evaluate.load(\"recall\")\n",
    "    metric3 = evaluate.load(\"f1\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric0.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
    "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
    "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing dataset...\n",
      "label\n",
      "negative    1525\n",
      "neutral     1281\n",
      "positive    1000\n",
      "Name: count, dtype: int64\n",
      "New sizes: label\n",
      "negative    1000\n",
      "positive    1000\n",
      "neutral     1000\n",
      "Name: count, dtype: int64\n",
      "Dataset loaded and prepared\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 99\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 99\n",
      "})\n",
      "Splitting dataset...\n",
      "Dataset splitted into train (60%), valid (20%) and test (20%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 484.50ba/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset:  59\n",
      "Length of valid dataset:  20\n",
      "Length of test dataset:  20\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Map: 100%|██████████| 59/59 [00:00<00:00, 3971.75 examples/s]\n",
      "\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 5175.92 examples/s]\n",
      "\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 4873.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset tokenized\n",
      "Loading model (NbAiLab/nb-bert-large)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preparing dataset...\")\n",
    "dataset, dataset_pd = load_and_prepare_dataset(path)\n",
    "print(dataset)\n",
    "\n",
    "print(\"Splitting dataset...\")\n",
    "dataset_splitted_dict = split_dataset(dataset)\n",
    "\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = tokenize_dataset(dataset_splitted_dict)\n",
    "\n",
    "print(\"Loading model (NbAiLab/nb-bert-large)...\")\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `df` is your DataFrame and 'label' your column name\n",
    "# First, create a dictionary that maps the current labels to the new numeric values\n",
    "label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "# Use the replace method to update the 'label' column\n",
    "dataset_pd['label'] = dataset_pd['label'].replace(label_mapping)\n",
    "\n",
    "# Now df['label'] should contain the numeric values 0, 1, 2 instead of the string labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split of the pandas dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(dataset_pd, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at NbAiLab/nb-bert-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Output directory (outputs/) already exists and is not empty. Set overwrite_output_dir: True to automatically overwrite.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 22\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m ClassificationModel(\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNbAiLab/nb-bert-large\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     use_cuda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m ) \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:547\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_dir\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    543\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(output_dir)\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(output_dir)\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moverwrite_output_dir\n\u001b[1;32m    546\u001b[0m ):\n\u001b[0;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput directory (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) already exists and is not empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Set overwrite_output_dir: True to automatically overwrite.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    550\u001b[0m             output_dir\n\u001b[1;32m    551\u001b[0m         )\n\u001b[1;32m    552\u001b[0m     )\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_model_to_device()\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_hf_datasets:\n",
      "\u001b[0;31mValueError\u001b[0m: Output directory (outputs/) already exists and is not empty. Set overwrite_output_dir: True to automatically overwrite."
     ]
    }
   ],
   "source": [
    "# usning simple transformers\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)\n",
    "\n",
    "model_args = ClassificationArgs(num_train_epochs=3)\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(\n",
    "    'bert',\n",
    "    'NbAiLab/nb-bert-large',\n",
    "    num_labels=3,\n",
    "    args=model_args,\n",
    "    use_cuda=False\n",
    ") \n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/simpletransformers/classification/classification_model.py:1454: UserWarning: Dataframe headers not specified. Falling back to using column 0 as text and column 1 as labels.\n",
      "  warnings.warn(\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "Python(6669) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6670) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6671) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6672) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6673) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6674) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6675) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6676) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "  5%|▌         | 1/20 [00:05<01:41,  5.36s/it]\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_3_2\n",
      "Running Evaluation: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': -0.04950737714883372, 'eval_loss': 1.1298232475916545, 'f1': 0.35, 'acc': 0.35}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.75      0.48         8\n",
      "     neutral       0.00      0.00      0.00         8\n",
      "    positive       0.33      0.25      0.29         4\n",
      "\n",
      "    accuracy                           0.35        20\n",
      "   macro avg       0.23      0.33      0.26        20\n",
      "weighted avg       0.21      0.35      0.25        20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def f1_multiclass(labels, preds):\n",
    "    return f1_score(labels, preds, average='micro')\n",
    "    \n",
    "\n",
    "result, model_outputs, wrong_predictions = model.eval_model(test_df, f1=f1_multiclass, acc=accuracy_score)\n",
    "\n",
    "\n",
    "# get a classification report \n",
    "from sklearn.metrics import classification_report\n",
    "y_true = test_df['label']\n",
    "y_pred = model_outputs.argmax(axis=1)\n",
    "target_names = ['negative', 'neutral', 'positive']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': -0.04950737714883372, 'f1': 0.35, 'acc': 0.35, 'eval_loss': 1.1298232475916545}\n",
      "[[ 1.95080474e-01 -1.74649432e-01 -1.04023919e-01]\n",
      " [ 7.08302796e-01  3.16931792e-02 -4.08638567e-01]\n",
      " [ 2.86453724e-01 -2.92465866e-01 -2.92772382e-01]\n",
      " [ 6.71456158e-01  1.39731169e-01 -4.92017478e-01]\n",
      " [ 2.20730767e-01 -2.07033291e-01 -9.06951576e-02]\n",
      " [ 3.39657485e-01 -1.90712675e-01 -6.74650967e-02]\n",
      " [ 1.75995007e-03 -2.53603041e-01 -1.59949791e-02]\n",
      " [ 9.43301171e-02 -2.87042081e-01 -1.11295491e-01]\n",
      " [ 1.76694021e-01 -3.36882830e-01 -3.68512660e-01]\n",
      " [ 9.80528593e-02 -4.33587670e-01  2.23039404e-01]\n",
      " [ 9.27601010e-04 -3.64341319e-01  1.54874668e-01]\n",
      " [ 5.71119845e-01 -6.36255518e-02 -2.40721121e-01]\n",
      " [ 1.27076596e-01 -2.12510571e-01 -2.66325057e-01]\n",
      " [ 1.83867738e-01 -3.84387314e-01 -3.13319534e-01]\n",
      " [ 1.82468370e-01 -2.34703198e-01 -1.08885556e-01]\n",
      " [ 1.75938472e-01 -2.07500592e-01 -1.70884892e-01]\n",
      " [ 1.57920465e-01 -2.65615702e-01 -1.62593961e-01]\n",
      " [-9.81983393e-02 -2.77918935e-01  3.59228589e-02]\n",
      " [ 1.56672657e-01 -2.54229546e-01  2.31568106e-02]\n",
      " [ 5.65934926e-04 -2.02338442e-01 -6.89119250e-02]]\n",
      "[{'guid': 1, 'text_a': 'RT @USER: En AaB-legende siger stop #sldk', 'text_b': None, 'label': 1}, {'guid': 2, 'text_a': 'For mig var det Google Ads på diverse mediers sider', 'text_b': None, 'label': 1}, {'guid': 4, 'text_a': \"0-1 AaB-Vejle Boldklub! '6: Mål af Gustaf Nilsson, Vejle Boldklub\", 'text_b': None, 'label': 2}, {'guid': 5, 'text_a': 'I påsken er jeg på sidelinien her…\\nTors #fckfcm\\nFre #obfcn\\nSøn ViborgFF vs Næstved\\nSøn #vbagf\\nMan #rfcaab\\nMan #fcmbif\\n#sldk #NordicBetLigaen', 'text_b': None, 'label': 1}, {'guid': 7, 'text_a': 'Det kunne være en super drøm, ingen tvivl om det.\\n\\nMen vi skal vente noget tid før det sker da vi 100 procent kommer ind på stabilitet som stadigvæk halter lige pt. Dog er jeg overrasket over at der er ikke sket de helt store udsving fra det afsluttende CPH Games.', 'text_b': None, 'label': 2}, {'guid': 8, 'text_a': 'Skal du med ud og samle affald på søndag? ♻️🥫🚬\\nDer er mere end tusind lokale indsamlinger tilmeldt den store affaldsindsamling på søndag. Find en indsamling nær dig og blive affaldshelt for en dag 👉 #dkgreen #TrashTag #affaldsindsamlingen', 'text_b': None, 'label': 2}, {'guid': 9, 'text_a': 'Jeg tror, det der var kampen. Goff virker lost', 'text_b': None, 'label': 0}, {'guid': 11, 'text_a': 'Spar rejseforsikringen, det er trods alt kun meget få der rammes af sygdom og ulykker på ferien #dkpol #dkmedier', 'text_b': None, 'label': 1}, {'guid': 12, 'text_a': 'Netop min tanke. Kan det være en slags happening, der skal skabe opmærksomhed om misinformation på nettet før valgene?', 'text_b': None, 'label': 1}, {'guid': 13, 'text_a': 'Godt nok er du bibliotrice, men nej det her kan jeg dokumentere 😜', 'text_b': None, 'label': 1}, {'guid': 16, 'text_a': 'kommer til at hjælpe med at strømline og eksekvere Strategi 6.4. Og selvfølgelig skal vores presspil nuanceres og udvikles, men det kommer den nye træner til at stå for. Tror ikke vi kommer til at være så ultimative i presset, som under AZ, men mindre er også ok.', 'text_b': None, 'label': 1}, {'guid': 17, 'text_a': 'Eller fordi det er godt at se hvor dårligt livet var før i tiden. De gode gamle dage findes ikke', 'text_b': None, 'label': 0}, {'guid': 18, 'text_a': 'Kronik: Holocaust: Vi har alle et ansvar for ikke at glemme', 'text_b': None, 'label': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(model_outputs)\n",
    "print(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': -0.04950737714883372, 'eval_loss': 1.1298232475916545}\n",
      "\n",
      "[[ 1.95080474e-01 -1.74649432e-01 -1.04023919e-01]\n",
      " [ 7.08302796e-01  3.16931792e-02 -4.08638567e-01]\n",
      " [ 2.86453724e-01 -2.92465866e-01 -2.92772382e-01]\n",
      " [ 6.71456158e-01  1.39731169e-01 -4.92017478e-01]\n",
      " [ 2.20730767e-01 -2.07033291e-01 -9.06951576e-02]\n",
      " [ 3.39657485e-01 -1.90712675e-01 -6.74650967e-02]\n",
      " [ 1.75995007e-03 -2.53603041e-01 -1.59949791e-02]\n",
      " [ 9.43301171e-02 -2.87042081e-01 -1.11295491e-01]\n",
      " [ 1.76694021e-01 -3.36882830e-01 -3.68512660e-01]\n",
      " [ 9.80528593e-02 -4.33587670e-01  2.23039404e-01]\n",
      " [ 9.27601010e-04 -3.64341319e-01  1.54874668e-01]\n",
      " [ 5.71119845e-01 -6.36255518e-02 -2.40721121e-01]\n",
      " [ 1.27076596e-01 -2.12510571e-01 -2.66325057e-01]\n",
      " [ 1.83867738e-01 -3.84387314e-01 -3.13319534e-01]\n",
      " [ 1.82468370e-01 -2.34703198e-01 -1.08885556e-01]\n",
      " [ 1.75938472e-01 -2.07500592e-01 -1.70884892e-01]\n",
      " [ 1.57920465e-01 -2.65615702e-01 -1.62593961e-01]\n",
      " [-9.81983393e-02 -2.77918935e-01  3.59228589e-02]\n",
      " [ 1.56672657e-01 -2.54229546e-01  2.31568106e-02]\n",
      " [ 5.65934926e-04 -2.02338442e-01 -6.89119250e-02]]\n",
      "\n",
      "[{'guid': 1, 'text_a': 'RT @USER: En AaB-legende siger stop #sldk', 'text_b': None, 'label': 1}, {'guid': 2, 'text_a': 'For mig var det Google Ads på diverse mediers sider', 'text_b': None, 'label': 1}, {'guid': 4, 'text_a': \"0-1 AaB-Vejle Boldklub! '6: Mål af Gustaf Nilsson, Vejle Boldklub\", 'text_b': None, 'label': 2}, {'guid': 5, 'text_a': 'I påsken er jeg på sidelinien her…\\nTors #fckfcm\\nFre #obfcn\\nSøn ViborgFF vs Næstved\\nSøn #vbagf\\nMan #rfcaab\\nMan #fcmbif\\n#sldk #NordicBetLigaen', 'text_b': None, 'label': 1}, {'guid': 7, 'text_a': 'Det kunne være en super drøm, ingen tvivl om det.\\n\\nMen vi skal vente noget tid før det sker da vi 100 procent kommer ind på stabilitet som stadigvæk halter lige pt. Dog er jeg overrasket over at der er ikke sket de helt store udsving fra det afsluttende CPH Games.', 'text_b': None, 'label': 2}, {'guid': 8, 'text_a': 'Skal du med ud og samle affald på søndag? ♻️🥫🚬\\nDer er mere end tusind lokale indsamlinger tilmeldt den store affaldsindsamling på søndag. Find en indsamling nær dig og blive affaldshelt for en dag 👉 #dkgreen #TrashTag #affaldsindsamlingen', 'text_b': None, 'label': 2}, {'guid': 9, 'text_a': 'Jeg tror, det der var kampen. Goff virker lost', 'text_b': None, 'label': 0}, {'guid': 11, 'text_a': 'Spar rejseforsikringen, det er trods alt kun meget få der rammes af sygdom og ulykker på ferien #dkpol #dkmedier', 'text_b': None, 'label': 1}, {'guid': 12, 'text_a': 'Netop min tanke. Kan det være en slags happening, der skal skabe opmærksomhed om misinformation på nettet før valgene?', 'text_b': None, 'label': 1}, {'guid': 13, 'text_a': 'Godt nok er du bibliotrice, men nej det her kan jeg dokumentere 😜', 'text_b': None, 'label': 1}, {'guid': 16, 'text_a': 'kommer til at hjælpe med at strømline og eksekvere Strategi 6.4. Og selvfølgelig skal vores presspil nuanceres og udvikles, men det kommer den nye træner til at stå for. Tror ikke vi kommer til at være så ultimative i presset, som under AZ, men mindre er også ok.', 'text_b': None, 'label': 1}, {'guid': 17, 'text_a': 'Eller fordi det er godt at se hvor dårligt livet var før i tiden. De gode gamle dage findes ikke', 'text_b': None, 'label': 0}, {'guid': 18, 'text_a': 'Kronik: Holocaust: Vi har alle et ansvar for ikke at glemme', 'text_b': None, 'label': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(\"\")\n",
    "print(model_outputs)\n",
    "print(\"\")\n",
    "print(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "Python(6519) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6521) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6522) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6523) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6524) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6525) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6526) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Python(6527) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.46s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the model\n",
    "predictions, raw_outputs = model.predict([\"Sam was a Wizard\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 4 # stating batch size\n",
    "epochs = 2\n",
    "learning_rate = 2e-5\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  num_train_epochs=epochs,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  learning_rate=learning_rate,\n",
    "                                  weight_decay=0.01,\n",
    "                                  logging_dir=\"logs\",\n",
    "                                  logging_steps=10,\n",
    "                                  load_best_model_at_end=True,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  save_strategy=\"epoch\",  # Add this line\n",
    "                                  remove_unused_columns=False,\n",
    "                                  run_name=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/420 [02:02<?, ?it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 6.07 GB, other allocations: 11.64 GB, max allowed: 18.13 GB). Tried to allocate 732.43 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/transformers/trainer.py:1910\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\n\u001b[1;32m   1905\u001b[0m             model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m   1906\u001b[0m             args\u001b[38;5;241m.\u001b[39mmax_grad_norm,\n\u001b[1;32m   1907\u001b[0m         )\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 1910\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1911\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/accelerate/optimizer.py:145\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    171\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    174\u001b[0m         group,\n\u001b[1;32m    175\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         state_steps,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 335\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/torch/optim/adamw.py:464\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    462\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    466\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 6.07 GB, other allocations: 11.64 GB, max allowed: 18.13 GB). Tried to allocate 732.43 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:18<00:00,  3.88it/s]/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 70/70 [00:23<00:00,  2.93it/s]\n",
      "100%|██████████| 70/70 [00:18<00:00,  4.00it/s]/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 70/70 [00:23<00:00,  3.03it/s]\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 70/70 [00:18<00:00,  3.91it/s]/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 70/70 [00:23<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.34285714285714286, 'precision': 0.11755102040816326, 'recall': 0.34285714285714286, 'f1': 0.17507598784194528}\n",
      "{'accuracy': 0.33989266547406083, 'precision': 0.11552702404306182, 'recall': 0.33989266547406083, 'f1': 0.17244220678256755}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# creating model predictions for the validation data\n",
    "predictions_val = trainer.predict(tokenized_dataset[\"valid\"])\n",
    "\n",
    "# choosing the prediction that has the highest probability \n",
    "preds_val_val = np.argmax(predictions_val.predictions, axis=-1)\n",
    "\n",
    "# calculating the probabilities instead of logits from each\n",
    "predictions_probabilities = tf.nn.softmax(predictions_val.predictions)\n",
    "\n",
    "def compute_metrics_end(preds, refs):\n",
    "    metric0 = evaluate.load(\"accuracy\")\n",
    "    metric1 = evaluate.load(\"precision\")\n",
    "    metric2 = evaluate.load(\"recall\")\n",
    "    metric3 = evaluate.load(\"f1\")\n",
    "    \n",
    "    #logits, labels = eval_pred\n",
    "    #predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric0.compute(predictions=preds, references=refs)[\"accuracy\"]\n",
    "    precision = metric1.compute(predictions=preds, references=refs, average=\"weighted\")[\"precision\"]\n",
    "    recall = metric2.compute(predictions=preds, references=refs, average=\"weighted\")[\"recall\"]\n",
    "    f1 = metric3.compute(predictions=preds, references=refs, average=\"weighted\")[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "metrics_val = compute_metrics_end(preds=preds_val_val, refs=predictions_val.label_ids)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# creating model predictions for the validation data\n",
    "predictions_test = trainer.predict(tokenized_dataset[\"test\"])\n",
    "\n",
    "# choosing the prediction that has the highest probability \n",
    "preds_test_test = np.argmax(predictions_test.predictions, axis=-1)\n",
    "\n",
    "# calculating the probabilities instead of logits from each\n",
    "predictions_probabilities_test = tf.nn.softmax(predictions_test.predictions)\n",
    "\n",
    "metrics_test = compute_metrics_end(preds=preds_test_test, refs=predictions_test.label_ids)\n",
    "\n",
    "print(metrics_test)\n",
    "print(metrics_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'Predicted Labels': [\"negative\" if i == 0 else \"neutral\" if i == 1 else \"positive\" for i in preds_val_val],\n",
    "        'True Labels': [\"negative\" if i == 0 else \"neutral\" if i == 1 else \"positive\" for i in predictions_val.label_ids],\n",
    "        'Misclassification': [\"TRUE\" if preds_val_val[i] == predictions_val.label_ids[i] else 'MISS' for i, val in enumerate(preds_val_val)],\n",
    "        'Text': dataset_splitted_dict['valid']['text'],\n",
    "        'Logit Values': [str(i) for i in predictions_val.predictions],\n",
    "        'Probabilities': [str(i) for i in np.asarray(predictions_probabilities)]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       197\n",
      "     neutral       0.00      0.00      0.00       172\n",
      "    positive       0.34      1.00      0.51       190\n",
      "\n",
      "    accuracy                           0.34       559\n",
      "   macro avg       0.11      0.33      0.17       559\n",
      "weighted avg       0.12      0.34      0.17       559\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Extract the true and predicted labels\n",
    "true_labels = df['True Labels']\n",
    "predicted_labels = df['Predicted Labels']\n",
    "\n",
    "# Create a mapping for the labels to numbers if needed\n",
    "label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "\n",
    "# Map the labels to numbers using the mapping\n",
    "true_labels_mapped = true_labels.map(label_mapping)\n",
    "predicted_labels_mapped = predicted_labels.map(label_mapping)\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_labels_mapped, predicted_labels_mapped, target_names=label_mapping.keys())\n",
    "\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>True Labels</th>\n",
       "      <th>Misclassification</th>\n",
       "      <th>Text</th>\n",
       "      <th>Logit Values</th>\n",
       "      <th>Probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Nu er det så Swedbank og €135 milliarder, og e...</td>\n",
       "      <td>[-0.39701766 -0.42288524 -0.28771487]</td>\n",
       "      <td>[0.32362834 0.3153642  0.36100742]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Aha. Du betegner det som to lag vælgere, og de...</td>\n",
       "      <td>[-0.3970175  -0.42288476 -0.28771502]</td>\n",
       "      <td>[0.32362837 0.31536436 0.36100736]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Bedre udbud for alle, styrket konkurrence og l...</td>\n",
       "      <td>[-0.39701766 -0.42288476 -0.28771493]</td>\n",
       "      <td>[0.3236283  0.31536433 0.3610074 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Præcis, den med englændere på ferie er også ge...</td>\n",
       "      <td>[-0.39701957 -0.42288882 -0.28771558]</td>\n",
       "      <td>[0.3236284  0.31536373 0.3610079 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>MISS</td>\n",
       "      <td>RT @USER: Dagens bedste respons på Rasmus P. d...</td>\n",
       "      <td>[-0.3970187  -0.42288706 -0.28771544]</td>\n",
       "      <td>[0.3236284  0.31536397 0.36100763]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Det er en bot der ændrer billedet hele tiden.</td>\n",
       "      <td>[-0.39702025 -0.42289037 -0.2877158 ]</td>\n",
       "      <td>[0.32362843 0.31536347 0.3610081 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>MISS</td>\n",
       "      <td>#sundpol læs med hos Zetland. Hvor mange flere...</td>\n",
       "      <td>[-0.39701933 -0.4228887  -0.28771564]</td>\n",
       "      <td>[0.3236284  0.3153637  0.36100784]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>RT @USER: Billund Kommune ❤️ jeg er vild med j...</td>\n",
       "      <td>[-0.39701957 -0.422889   -0.28771555]</td>\n",
       "      <td>[0.3236284  0.31536368 0.36100793]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Mette Frederiksen til pressen: - I skal opføre...</td>\n",
       "      <td>[-0.39701986 -0.42288983 -0.2877158 ]</td>\n",
       "      <td>[0.32362846 0.31536356 0.36100802]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>Belgien undskylder for at fjerne børn fra dere...</td>\n",
       "      <td>[-0.39701736 -0.42288423 -0.28771484]</td>\n",
       "      <td>[0.3236283  0.31536442 0.3610073 ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted Labels True Labels Misclassification  \\\n",
       "0           positive    negative              MISS   \n",
       "1           positive    negative              MISS   \n",
       "2           positive    positive              TRUE   \n",
       "3           positive    positive              TRUE   \n",
       "4           positive    negative              MISS   \n",
       "..               ...         ...               ...   \n",
       "554         positive    negative              MISS   \n",
       "555         positive     neutral              MISS   \n",
       "556         positive    positive              TRUE   \n",
       "557         positive    negative              MISS   \n",
       "558         positive    positive              TRUE   \n",
       "\n",
       "                                                  Text  \\\n",
       "0    Nu er det så Swedbank og €135 milliarder, og e...   \n",
       "1    Aha. Du betegner det som to lag vælgere, og de...   \n",
       "2    Bedre udbud for alle, styrket konkurrence og l...   \n",
       "3    Præcis, den med englændere på ferie er også ge...   \n",
       "4    RT @USER: Dagens bedste respons på Rasmus P. d...   \n",
       "..                                                 ...   \n",
       "554      Det er en bot der ændrer billedet hele tiden.   \n",
       "555  #sundpol læs med hos Zetland. Hvor mange flere...   \n",
       "556  RT @USER: Billund Kommune ❤️ jeg er vild med j...   \n",
       "557  Mette Frederiksen til pressen: - I skal opføre...   \n",
       "558  Belgien undskylder for at fjerne børn fra dere...   \n",
       "\n",
       "                              Logit Values                       Probabilities  \n",
       "0    [-0.39701766 -0.42288524 -0.28771487]  [0.32362834 0.3153642  0.36100742]  \n",
       "1    [-0.3970175  -0.42288476 -0.28771502]  [0.32362837 0.31536436 0.36100736]  \n",
       "2    [-0.39701766 -0.42288476 -0.28771493]  [0.3236283  0.31536433 0.3610074 ]  \n",
       "3    [-0.39701957 -0.42288882 -0.28771558]  [0.3236284  0.31536373 0.3610079 ]  \n",
       "4    [-0.3970187  -0.42288706 -0.28771544]  [0.3236284  0.31536397 0.36100763]  \n",
       "..                                     ...                                 ...  \n",
       "554  [-0.39702025 -0.42289037 -0.2877158 ]  [0.32362843 0.31536347 0.3610081 ]  \n",
       "555  [-0.39701933 -0.4228887  -0.28771564]  [0.3236284  0.3153637  0.36100784]  \n",
       "556  [-0.39701957 -0.422889   -0.28771555]  [0.3236284  0.31536368 0.36100793]  \n",
       "557  [-0.39701986 -0.42288983 -0.2877158 ]  [0.32362846 0.31536356 0.36100802]  \n",
       "558  [-0.39701736 -0.42288423 -0.28771484]  [0.3236283  0.31536442 0.3610073 ]  \n",
       "\n",
       "[559 rows x 6 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdf_metrics_val = pd.DataFrame(metrics_val.items())\n",
    "df_metrics_test = pd.DataFrame(metrics_test.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.339893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.115527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.339893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.172442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   accuracy  0.339893\n",
       "1  precision  0.115527\n",
       "2     recall  0.339893\n",
       "3         f1  0.172442"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdf_metrics_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.117551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.342857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.175076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   accuracy  0.342857\n",
       "1  precision  0.117551\n",
       "2     recall  0.342857\n",
       "3         f1  0.175076"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.28it/s]/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1325998306274414,\n",
       " 'eval_accuracy': 0.3,\n",
       " 'eval_precision': 0.1,\n",
       " 'eval_recall': 0.3,\n",
       " 'eval_f1': 0.15,\n",
       " 'eval_runtime': 8.011,\n",
       " 'eval_samples_per_second': 2.497,\n",
       " 'eval_steps_per_second': 0.374,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  7.63it/s]/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.79s/it]\n",
      "100%|██████████| 3/3 [00:00<00:00,  8.35it/s]/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.99s/it]\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/wibe/Desktop/CogSci/NLP/NLP_exam_2023/venv_NLP_exam/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# get a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(trainer.predict(tokenized_dataset['valid']).label_ids, trainer.predict(tokenized_dataset['valid']).predictions.argmax(-1), target_names=['negative', 'neutral', 'positive'], output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score  support\n",
      "negative       0.000000  0.000000  0.000000     8.00\n",
      "neutral        0.000000  0.000000  0.000000     6.00\n",
      "positive       0.263158  0.833333  0.400000     6.00\n",
      "accuracy       0.250000  0.250000  0.250000     0.25\n",
      "macro avg      0.087719  0.277778  0.133333    20.00\n",
      "weighted avg   0.078947  0.250000  0.120000    20.00\n"
     ]
    }
   ],
   "source": [
    "# classification report as a dataframe\n",
    "print(pd.DataFrame(report).transpose())\n",
    "\n",
    "# save the report as a csv file\n",
    "#pd.DataFrame(report).transpose().to_csv('classification_reports/classification_report_without_paraphrasings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_NLP_exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
